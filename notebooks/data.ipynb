{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state_cd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kranz-michael\\Cmder\\vendor\\miniconda3\\envs\\heal-stigma-state-lvl\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\kranz-michael\\Cmder\\vendor\\miniconda3\\envs\\heal-stigma-state-lvl\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kranz-michael\\Cmder\\vendor\\miniconda3\\envs\\heal-stigma-state-lvl\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state_cd'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m     field \u001b[38;5;241m=\u001b[39m fl\u001b[38;5;241m.\u001b[39mField\u001b[38;5;241m.\u001b[39mfrom_descriptor(field)\n\u001b[0;32m     43\u001b[0m     schema\u001b[38;5;241m.\u001b[39madd_field(field)\n\u001b[1;32m---> 44\u001b[0m     targetdf[field\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43msourcedf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m## 6 question\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mapping \u001b[38;5;129;01min\u001b[39;00m mappings\u001b[38;5;241m.\u001b[39mstigma6\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\kranz-michael\\Cmder\\vendor\\miniconda3\\envs\\heal-stigma-state-lvl\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\kranz-michael\\Cmder\\vendor\\miniconda3\\envs\\heal-stigma-state-lvl\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state_cd'"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "process data and save in data/processed folder\n",
    "TODO: refactor code in the data module (right now I just copy/pasted the relevant code from the legacy notebook in `data`)\n",
    "TODO: make custom Field objects and transform Steps to make metadata more readable\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# import packages\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "import frictionless as fl\n",
    "\n",
    "from stigma_state_lvl.data import mappings, metadata, transforms\n",
    "from stigma_state_lvl.data.metadata import fields\n",
    "\n",
    "# %% [markdown]\n",
    "# %%\n",
    "# import data and metadata (data dictionaries)\n",
    "# datapath = Path(__file__).parents[1]/\"wave1.sav\"\n",
    "datapath = \"../data/raw/wave1.sav\"\n",
    "sourcedf, sourcemeta = pyreadstat.read_sav(datapath, apply_value_formats=True)\n",
    "source_variablelabels = {\n",
    "    name.lower(): label for name, label in sourcemeta.column_names_to_labels.items()\n",
    "}\n",
    "# lower-case column names\n",
    "sourcedf.columns = sourcedf.columns.str.lower()\n",
    "\n",
    "# INITIATE TARGET SCHEMA AND DATAFRAME\n",
    "# TODO: change df to targetdf in all below code\n",
    "df = targetdf = sourcedf[[\"caseid\"]].copy()\n",
    "\n",
    "schema = fl.Schema(fields=[fl.Field.from_descriptor(metadata.fields.caseid)])\n",
    "\n",
    "# POPULATE TARGET SCHEMA AND DF\n",
    "for field in fields.demographic:\n",
    "    field = fl.Field.from_descriptor(field)\n",
    "    schema.add_field(field)\n",
    "    targetdf[field.name] = sourcedf[field.name]\n",
    "\n",
    "## 6 question\n",
    "for name, mapping in mappings.stigma6.items():\n",
    "    _meta = {\n",
    "        \"name\": name,\n",
    "        \"description\": source_variablelabels[name],\n",
    "        \"enumLabels\": mapping,\n",
    "        **metadata.stigma6,\n",
    "    }\n",
    "    data, meta = transforms.categorical_to_numeric(\n",
    "        data=sourcedf[name], mapping=mapping, meta=_meta\n",
    "    )\n",
    "    targetdf[name] = data\n",
    "    schema.add_field(fl.Field.from_descriptor(meta))\n",
    "\n",
    "## 10 question\n",
    "for name, mapping in mappings.stigma10.items():\n",
    "    _meta = {\n",
    "        \"name\": name,\n",
    "        \"description\": source_variablelabels[name],\n",
    "        \"enumLabels\": mapping,\n",
    "        **metadata.stigma10,\n",
    "    }\n",
    "    data, meta = data.categorical_to_numeric(\n",
    "        data=sourcedf[name], mapping=mapping, meta=_meta\n",
    "    )\n",
    "    targetdf[name] = data\n",
    "    schema.add_field(fl.Field.from_descriptor(meta))\n",
    "\n",
    "# current and past usage\n",
    "\n",
    "## 6 question\n",
    "for field in fields.ss_6_past:\n",
    "    data = sourcedf[field[\"name\"]].copy() # TODO: change to numeric (right now, already calculated so not doing)\n",
    "    targetdf[meta[\"name\"]] = data\n",
    "    schema.add_field(fl.Field.from_descriptor(field))\n",
    "\n",
    "meta = fl.Field.from_descriptor(fl.Field.from_descriptor(fields.derived_ss_6_past))\n",
    "meta.description += (\"\\n**Transforms**\\n\"\n",
    "            f\"The mean of  `{'`,`'.join(ss_6_past_names)}`\")\n",
    "schema.add_field(meta)\n",
    "df[\"ss_6_past\"] = df[ss_6_past_names].mean(axis=1)\n",
    "\n",
    "for field in fields.ss_6_current:\n",
    "    data = sourcedf[field[\"name\"]].copy() # TODO: change to numeric (right now, already calculated so not doing)\n",
    "    targetdf[meta[\"name\"]] = data\n",
    "    schema.add_field(fl.Field.from_descriptor(field))\n",
    "\n",
    "\n",
    "meta = fl.Field.from_descriptor(fields.derived_ss_6_current)\n",
    "meta.description += (\"\\n**Transforms**\\n\"\n",
    "            f\"The mean of  `{'`,`'.join(ss_6_current_vars)}`\")\n",
    "schema.add_field(fl.Field.from_descriptor(meta))\n",
    "df[\"ss_6_current\"] = df[ss_6_current_vars].mean(axis=1)\n",
    "\n",
    "## 10 question\n",
    "ss_10_past_names = [field[\"name\"] for field in fields.ss_10_past + fields.ss_6_past]\n",
    "df[\"ss_10_past\"] = df[ss_10_past_names].mean(axis=1)\n",
    "meta.description += (\"\\n**Transforms**\\n\"\n",
    "            f\"The mean of  `{'`,`'.join(ss_10_past_names)}`\")\n",
    "schema.add_field(fl.Field.from_descriptor(meta))\n",
    "df[\"ss_10_current\"] = df[ss_10_past_names].mean(axis=1)\n",
    "\n",
    "## Cobra racial awareness\n",
    "\n",
    "for name, mapping in mappings.cobra.items():\n",
    "\n",
    "    data, meta = data.categorical_to_numeric(\n",
    "        data=sourcedf[name], mapping=mapping, meta=metadata.cobra\n",
    "    )\n",
    "    targetdf[name] = data\n",
    "    schema.add_field(fl.Field.from_descriptor(meta))\n",
    "\n",
    "\n",
    "df[\"racial_privilege\"] = df[cobramap.keys()].sum(axis=1)\n",
    "meta = fields.cobra_composite\n",
    "meta.description += (\"\\n**Transforms**\\n\"\n",
    "            f\"The sum of  `{'`,`'.join(ss_10_past_names)}`\")\n",
    "schema.add_field(fl.Field.from_descriptor(meta))\n",
    "\n",
    "vars_of_interest = [\n",
    "    \"stigma_scale_score\",\n",
    "    \"expanded_10item_stigma\",\n",
    "    \"personaluse_ever\",\n",
    "    \"familyuse_ever\",\n",
    "    \"personalcrimjust_ever\",\n",
    "    \"familycrimjust_ever\",\n",
    "]\n",
    "\n",
    "\n",
    "# clean up some of the categoricals to be consistently coded\n",
    "df.familycrimjust_ever.replace({0: \"No\", 1: \"Yes\"}, inplace=True)\n",
    "df.familyuse_ever.replace({\" No\": \"No\"}, inplace=True)\n",
    "df.personalcrimjust_ever.replace(\n",
    "    {\n",
    "        \"Yes, ever arrested or incarcerated\": \"Yes\",\n",
    "        \"No, never arrested or incarcerated\": \"No\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# # impute missing stigma scale score vals with median, impute missing personaluse_ever with mode, \"No\"\n",
    "# replace missing values of personaluse_ever with mode value of 'No'\n",
    "df.personaluse_ever.fillna(\"No\", inplace=True)\n",
    "df.familyuse_ever.fillna(\"No\", inplace=True)\n",
    "df.personalcrimjust_ever.fillna(\"No\", inplace=True)\n",
    "df.familycrimjust_ever.fillna(\"No\", inplace=True)\n",
    "\n",
    "# impute missing stigma scale score values as the median score\n",
    "# TODO: compute based on individual scores\n",
    "df[\"stigma_scale_score\"].fillna(df[\"stigma_scale_score\"].median(), inplace=True)\n",
    "df[\"expanded_10item_stigma\"].fillna(df[\"expanded_10item_stigma\"].median(), inplace=True)\n",
    "\n",
    "\n",
    "# %%\n",
    "# add df column with state 2 letter code\n",
    "# https://pythonfix.com/code/us-states-abbrev.py/\n",
    "# state name to two letter code dictionary\n",
    "for field in fields.jcoin_hub:\n",
    "    field = fl.Field.from_descriptor(field)\n",
    "    schema.add_field(field)\n",
    "    targetdf[field.name] = sourcedf[field.name]\n",
    "\n",
    "us_state_to_abbrev = package.get_resource(\"state-abbreviations\").read_data()\n",
    "state_cd = df.state.replace(us_state_to_abbrev)\n",
    "df.insert(6, \"state_cd\", state_cd, True)\n",
    "\n",
    "# %%\n",
    "# Add jcoin information\n",
    "jcoin_json = package.get_resource(\"jcoin-states\").read_data()\n",
    "\n",
    "jcoin_df = (\n",
    "    pd.DataFrame(jcoin_json)\n",
    "    .assign(hub_types=lambda df: df[\"hub\"] + \"(\" + df[\"type\"] + \")\")\n",
    "    .groupby(\"states\")\n",
    "    # make a list of the name and type of hub/study and how many hubs are in that state\n",
    "    .agg({\"hub_types\": lambda s: \",\".join(s), \"hub\": \"count\"})\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"states\": \"state_cd\",\n",
    "            \"hub\": \"jcoin_hub_count\",\n",
    "            \"hub_types\": \"jcoin_hub_types\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "jcoin_df[\"is_jcoin_state\"] = True\n",
    "\n",
    "# %%\n",
    "jcoin_df.head()\n",
    "\n",
    "# %%\n",
    "df = df.merge(jcoin_df, on=\"state_cd\", how=\"left\")\n",
    "df[\"jcoin_hub_types\"].fillna(\"not JCOIN\", inplace=True)\n",
    "df[\"jcoin_hub_count\"].fillna(0, inplace=True)\n",
    "df[\"is_jcoin_state\"].fillna(False, inplace=True)\n",
    "df[\"is_jcoin_hub\"] = np.where(df[\"jcoin_hub_types\"] == \"not JCOIN\", \"No\", \"Yes\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# join strata into dataset\n",
    "df = df.merge(df, on=\"caseid\", how=\"left\")\n",
    "\n",
    "pop_counts_by_sampletypexstate = (\n",
    "    df.convert_dtypes()\n",
    "    .assign(jcoin_hub_count=lambda df: df.jcoin_hub_count.astype(str))\n",
    "    .groupby([\"state_cd\", \"p_over\"])[\"stigma_scale_score\"]\n",
    "    .count()\n",
    "    .unstack([\"p_over\"])\n",
    ")\n",
    "pop_counts_by_sampletypexstate[\"total\"] = pop_counts_by_sampletypexstate.sum(axis=1)\n",
    "\n",
    "# %%\n",
    "# merge jcoin info\n",
    "pop_counts_by_sampletypexstate = (\n",
    "    pop_counts_by_sampletypexstate.merge(jcoin_df, on=\"state_cd\", how=\"left\")\n",
    "    .sort_values(\"total\", ascending=False)\n",
    "    .assign(\n",
    "        jcoin_hub_count=lambda df: df.jcoin_hub_count.fillna(0).astype(int),\n",
    "        jcoin_flag=lambda df: df.jcoin_flag.fillna(0).astype(int),\n",
    "        jcoin_hub_types=lambda df: (\n",
    "            np.where(\n",
    "                df.jcoin_hub_types.isna() & df[\"AS oversample\"] > 0,\n",
    "                \"non JCOIN comparison\",\n",
    "                np.where(\n",
    "                    df.jcoin_hub_types.isna(), \"non JCOIN gen pop\", df.jcoin_hub_types\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# strata/psus\n",
    "\n",
    "for field in fields.sampling + fields.weights:\n",
    "    field = fl.Field.from_descriptor(field)\n",
    "    schema.add_field(field)\n",
    "    targetdf[field.name] = sourcedf[field.name]\n",
    "\n",
    "\n",
    "states_with_oversample_df = pop_counts_by_sampletypexstate[\n",
    "    pop_counts_by_sampletypexstate[\"AS oversample\"] > 0\n",
    "]\n",
    "states_with_oversample_list = states_with_oversample_df[\"state_cd\"]\n",
    "df_as_oversample_states = df[df[\"state_cd\"].isin(states_with_oversample_list)]\n",
    "# get caseids for survey respondents in oversampled states\n",
    "caseid_in_as_oversample_state = df_as_oversample_states[\"caseid\"]\n",
    "strata_df = package.get_resource(\"strata-and-psu\").to_pandas()\n",
    "strata_df.columns = strata_df.columns.str.lower()\n",
    "# get strata and cluster ids for survey respondents in oversampled states\n",
    "strata_df_in_as_oversample_state = strata_df[\n",
    "    strata_df[\"caseid\"].isin(caseid_in_as_oversample_state)\n",
    "]\n",
    "# collapse strata containing only 1 PSU\n",
    "onepsu = (\n",
    "    strata_df[[\"vstrat32\", \"vpsu32\"]]\n",
    "    .drop_duplicates()\n",
    "    .groupby(\"vstrat32\")\n",
    "    .count()\n",
    "    .squeeze()\n",
    "    .loc[lambda s: s == 1]\n",
    "    .index\n",
    ")\n",
    "strata_df[\"vstrat32_corrected\"] = strata_df[\"vstrat32\"].where(\n",
    "    cond=lambda s: ~s.isin(onepsu), other=-1\n",
    ")\n",
    "# rename PSUs so no duplicates\n",
    "strata_df[\"vpsu32_corrected\"] = strata_df.groupby(\n",
    "    [\"vstrat32_corrected\", \"vpsu32\"]\n",
    ").ngroup()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# collapse strata containing only 1 PSU\n",
    "onepsu_in_as_oversample_state = (\n",
    "    strata_df_in_as_oversample_state[[\"vstrat32\", \"vpsu32\"]]\n",
    "    .drop_duplicates()\n",
    "    .groupby(\"vstrat32\")\n",
    "    .count()\n",
    "    .squeeze()\n",
    "    .loc[lambda s: s == 1]\n",
    "    .index\n",
    ")\n",
    "strata_df_in_as_oversample_state[\"vstrat32_corrected\"] = (\n",
    "    strata_df_in_as_oversample_state[\"vstrat32\"].where(\n",
    "        cond=lambda s: ~s.isin(onepsu_in_as_oversample_state), other=-1\n",
    "    )\n",
    ")\n",
    "# rename PSUs so no duplicates\n",
    "strata_df_in_as_oversample_state[\"vpsu32_corrected\"] = (\n",
    "    strata_df_in_as_oversample_state.groupby([\"vstrat32_corrected\", \"vpsu32\"]).ngroup()\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "# join strata into dataset\n",
    "\n",
    "fullsample_strata_df = strata_df.set_index(\"caseid\")[\n",
    "    [\"vstrat32_corrected\", \"vpsu32_corrected\"]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"vstrat32_corrected\": \"strata_fullsample\",\n",
    "        \"vpsu32_corrected\": \"psu_fullsample\",\n",
    "    }\n",
    ")\n",
    "oversample_strata_df = strata_df.set_index(\"caseid\")[\n",
    "    [\"vstrat32_corrected\", \"vpsu32_corrected\"]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"vstrat32_corrected\": \"strata_oversample\",\n",
    "        \"vpsu32_corrected\": \"psu_oversample\",\n",
    "    }\n",
    ")\n",
    "df = (\n",
    "    df.set_index(\"caseid\")\n",
    "    .join(fullsample_strata_df)\n",
    "    .join(oversample_strata_df)\n",
    "    .assign(\n",
    "        isin_state_with_oversample=lambda df: df.index.isin(\n",
    "            caseid_in_as_oversample_state\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "resource = fl.Resource(data=df.to_dict(orient=\"records\"),schema=schema)\n",
    "resource.schema.to_yaml(\"schemas/processed/protocol2_wave1_analytic.yaml\")\n",
    "resource.write(\"data/processed/protocol2_wave1_analytic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heal-stigma-state-lvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
